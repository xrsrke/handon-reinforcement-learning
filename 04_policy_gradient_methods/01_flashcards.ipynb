{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1003bed7-86f4-4c73-aeee-e452b681c1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gym\n",
    "from torch import nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c318ba6-625c-4f62-af68-ca57ef893ae9",
   "metadata": {},
   "source": [
    "### Discounted Rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170334ec-6e8e-4932-b67c-8f5f88331617",
   "metadata": {},
   "source": [
    "##### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "535d6ce6-4899-40e0-a0aa-6486b6c1df46",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = torch.tensor([1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "98c02128-319e-4325-bd34-44b951391c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5bc306-b8ae-4df7-a9f6-26bffaf1893b",
   "metadata": {},
   "source": [
    "Given `rewards` is the list of all predicted rewards from the current time step `0` to the next time step `3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "be86cd4c-f505-43fa-92ea-8b9b448ae291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4255d0ca-e7e6-437f-b23e-19dd6362110c",
   "metadata": {},
   "source": [
    "Write a function to calcualte the discounted reward at each time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a6af7de7-db88-4e12-8343-6a018adb3192",
   "metadata": {},
   "outputs": [],
   "source": [
    "discount_factor = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "15e8f0b6-abcf-4e61-abcd-c23e16cde6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discount_reward(rewards, discount_factor):\n",
    "    n_rewards = len(rewards)\n",
    "    timesteps = torch.arange(0, n_rewards)\n",
    "    \n",
    "    # calculate the discount for each time step\n",
    "    discount = torch.pow(discount_factor, timesteps)\n",
    "    discounted_rewards = discount * rewards\n",
    "\n",
    "    return discounted_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2bd486f3-4d62-47d7-a91c-420a80a8aedc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.9800, 2.9403, 3.8812])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discount_reward(rewards, discount_factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0580d1f2-1abd-409b-aebd-9afac66de07f",
   "metadata": {},
   "source": [
    "##### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8c7a2a65-09f1-4f49-971a-2eb0bf127bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.tensor([[0.1, 0.3, 0.6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "335963b0-ff2b-4b7b-a3ca-35e1d5efef9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95f46ab-2bb2-4a8a-8e68-13cd7a208bb1",
   "metadata": {},
   "source": [
    "`preds` is the probability distribution over the possible actions at the current time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2550a517-2b9c-4f1e-a40f-de20e5018100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1000, 0.3000, 0.6000]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc529f0-f6c0-449e-ac4f-e0a40fd87cc5",
   "metadata": {},
   "source": [
    "Sample an action from `preds` using PyTorch's built-in function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "37f28033-4248-41e3-8fd2-d5a1e7e27e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "action = torch.multinomial(preds, num_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "694b8d26-234a-4f82-8235-7933d2e50b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f180ef88-35bc-4980-a15a-b3b20bbb10ac",
   "metadata": {},
   "source": [
    "##### Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eeeb26a3-45c8-4193-bdbf-ea1114df4186",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.tensor([[0.1, 0.3, 0.6], [0.7, 0.2, 0.1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c9b3721-b1b0-4f8d-a2c1-82c0bda43b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "discounted_reward = torch.tensor([1.0, 0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5a2630-43f3-4201-9344-029ce846cc77",
   "metadata": {},
   "source": [
    "- `preds` is the probability distribution over the possible actions at each time step\n",
    "- `discounted_reward` is the distribution of discounted rewards at each time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bea6263e-08ef-4e52-a691-98b9fc5a5bfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1000, 0.3000, 0.6000],\n",
       "        [0.7000, 0.2000, 0.1000]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "179ad8cb-257c-4dda-b158-1da7fe552c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 0.5000])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discounted_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e0588f6-e53c-4697-9ae8-09d219be1a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(preds, discounted_rewards):\n",
    "    return -1 * torch.sum(discounted_rewards * torch.log(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30025c37-307c-4c8c-af1e-c1706aa963bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mloss_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscounted_reward\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m, in \u001b[0;36mloss_func\u001b[0;34m(preds, discounted_rewards)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss_func\u001b[39m(preds, discounted_rewards):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(\u001b[43mdiscounted_rewards\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "loss_func(preds, discounted_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bac6f9-bf3b-4e77-b122-bb4c55910a4e",
   "metadata": {},
   "source": [
    "### Transitions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21b0e4c-1c0a-4ae7-ac22-01b29030e737",
   "metadata": {},
   "source": [
    "##### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ceb7d35-c56d-498e-ae3c-3490368d2e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1')\n",
    "n_actions = env.action_space.n\n",
    "n_observations = env.observation_space.shape[0]\n",
    "hidden_size = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6d8c188-c655-41d4-9ad6-6065c124e86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(n_observations, hidden_size),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(hidden_size, n_actions),\n",
    "    nn.Softmax(dim=-1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b642df6-6f4f-4a9c-9c93-c546463ca6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17381b6-cdc3-4113-8bf5-4340e575ea6f",
   "metadata": {},
   "source": [
    "Write a function generate transitions in one episode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02846e5e-793d-4102-a8b3-6ae73cbf15c6",
   "metadata": {},
   "source": [
    "**Hint**: `env.step()` returns `next_state`, `reward`, `done`, `truncated` and `info`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a2f0c81-e588-48c6-aae0-c9f6545cebcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_transitions(model, env):\n",
    "    transitions = []\n",
    "    state, _ = env.reset()\n",
    "    \n",
    "    while True:\n",
    "        predicted_action = model(torch.from_numpy(state))\n",
    "        action = torch.argmax(predicted_action, dim=-1)\n",
    "        next_state, reward, done, truncated, info = env.step(action.item())\n",
    "        \n",
    "        transitions.append((\n",
    "            state, action, reward, next_state\n",
    "        ))\n",
    "        \n",
    "        if done: break\n",
    "        \n",
    "        state = next_state\n",
    "    \n",
    "    return transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9e6a911-d9a8-489a-ac35-679c4bd3cf10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.nn.modules.container.Sequential, gym.wrappers.time_limit.TimeLimit)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model), type(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "542d930f-7326-451b-9f5a-45c3ac9fd3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "transitions = generate_transitions(model, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9137bcc-14bd-424f-822a-bb160a30aef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([ 0.00905523,  0.02905998,  0.04682675, -0.00809694], dtype=float32),\n",
       "  tensor(1),\n",
       "  1.0,\n",
       "  array([ 0.00963643,  0.22348018,  0.04666481, -0.28564554], dtype=float32)),\n",
       " (array([ 0.00963643,  0.22348018,  0.04666481, -0.28564554], dtype=float32),\n",
       "  tensor(1),\n",
       "  1.0,\n",
       "  array([ 0.01410604,  0.4179066 ,  0.0409519 , -0.5632532 ], dtype=float32)),\n",
       " (array([ 0.01410604,  0.4179066 ,  0.0409519 , -0.5632532 ], dtype=float32),\n",
       "  tensor(1),\n",
       "  1.0,\n",
       "  array([ 0.02246417,  0.61243075,  0.02968683, -0.8427583 ], dtype=float32)),\n",
       " (array([ 0.02246417,  0.61243075,  0.02968683, -0.8427583 ], dtype=float32),\n",
       "  tensor(1),\n",
       "  1.0,\n",
       "  array([ 0.03471278,  0.80713516,  0.01283167, -1.1259596 ], dtype=float32)),\n",
       " (array([ 0.03471278,  0.80713516,  0.01283167, -1.1259596 ], dtype=float32),\n",
       "  tensor(1),\n",
       "  1.0,\n",
       "  array([ 0.05085549,  1.0020866 , -0.00968752, -1.4145904 ], dtype=float32)),\n",
       " (array([ 0.05085549,  1.0020866 , -0.00968752, -1.4145904 ], dtype=float32),\n",
       "  tensor(1),\n",
       "  1.0,\n",
       "  array([ 0.07089722,  1.1973273 , -0.03797933, -1.7102857 ], dtype=float32)),\n",
       " (array([ 0.07089722,  1.1973273 , -0.03797933, -1.7102857 ], dtype=float32),\n",
       "  tensor(1),\n",
       "  1.0,\n",
       "  array([ 0.09484377,  1.3928643 , -0.07218505, -2.014543  ], dtype=float32)),\n",
       " (array([ 0.09484377,  1.3928643 , -0.07218505, -2.014543  ], dtype=float32),\n",
       "  tensor(1),\n",
       "  1.0,\n",
       "  array([ 0.12270106,  1.588658  , -0.1124759 , -2.3286724 ], dtype=float32)),\n",
       " (array([ 0.12270106,  1.588658  , -0.1124759 , -2.3286724 ], dtype=float32),\n",
       "  tensor(1),\n",
       "  1.0,\n",
       "  array([ 0.15447421,  1.7846049 , -0.15904936, -2.653734  ], dtype=float32)),\n",
       " (array([ 0.15447421,  1.7846049 , -0.15904936, -2.653734  ], dtype=float32),\n",
       "  tensor(1),\n",
       "  1.0,\n",
       "  array([ 0.19016631,  1.9805219 , -0.21212403, -2.990464  ], dtype=float32))]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b96269-2b33-42d3-bc50-489849848a8e",
   "metadata": {},
   "source": [
    "### Discounted Return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b17ae93-a537-4930-b57d-3be45af735bb",
   "metadata": {},
   "source": [
    "##### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63bfcbfb-bdd2-42de-86a8-4bfc8565a641",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = torch.tensor([1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47710d8-88aa-4abe-a428-66a5252bd842",
   "metadata": {},
   "source": [
    "`rewards` is a list of rewards at each time step to an end of an episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95351442-7ad5-49e0-905e-b7ca41f853e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9581afde-f52d-48de-9e50-dcbede432f45",
   "metadata": {},
   "source": [
    "Write a function calculate **the discounted return of an episode**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f9dcf56-580b-4224-8d45-5295ed0c37a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_discounted_return(rewards, gamma=0.99):\n",
    "    total_return = torch.zeros(1)\n",
    "    discounted_returns = []\n",
    "    reversed_rewards = reversed(rewards)\n",
    "    \n",
    "    for reward in reversed_rewards:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa449cba-1f3a-428d-9580-c5effbf94bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 4, 3, 2, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_discounted_return(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238234bf-2d6a-4d0b-83df-835658f70a3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
