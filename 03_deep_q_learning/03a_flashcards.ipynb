{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "662c779a-72b5-4651-a5fa-49267bc646e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import gym\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5c04a8-e62d-4fa0-b290-95f541ee763c",
   "metadata": {},
   "source": [
    "**Example 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e3b008dd-d38c-47e1-be3d-df6267e0775e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import gym"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002a07e8-e67d-4bdc-aa81-d42c6f858ef2",
   "metadata": {},
   "source": [
    "Write a `DeepQNetwork` for `env`. Write hidden size is `128`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "64db40c0-772b-4f8e-86c8-45e9cb0d7d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "49d9fe10-8308-4fef-acca-73c5b7f844f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepQNetwork(nn.Module):\n",
    "    def __init__(self, n_observations, n_actions):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_observations, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, n_actions),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5d488767-efac-43f3-a51c-7544af498845",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_actions = env.action_space.n\n",
    "n_observations = env.observation_space.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f19f9128-104f-4c4d-8081-6648a5f2b6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepQNetwork(\n",
    "    n_observations=n_observations,\n",
    "    n_actions=n_actions\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae32826-c999-4e8c-8c22-91c9c8ad6c6f",
   "metadata": {},
   "source": [
    "##### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "63ab4a72-cdad-4c12-8195-8e6ab23b6584",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d59dfe-b4d6-4c94-b9b3-9635c1fe8125",
   "metadata": {},
   "source": [
    "Write a training loop for a Deep Q Network (no replay) and the agent will take action that has the highest predicted reward\n",
    "\n",
    "**Hint**\n",
    "- `env.step()` returns `new_observation, reward, done, truncated, info`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a1ded930-efc4-467f-8a58-52ee0a9475c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-2\n",
    "N_EPISODES = 100\n",
    "GAMMA = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5c782cc3-f7f5-43ed-a906-4ef83aef133b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.MSELoss()\n",
    "model = DeepQNetwork(n_observations=n_observations, n_actions=n_actions)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3f4bd0b4-95e6-445e-9a7d-a2130de742b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_episode in range(N_EPISODES):\n",
    "    observation, _ = env.reset()\n",
    "    observation = torch.from_numpy(observation)\n",
    "    in_progress = True\n",
    "    \n",
    "    while in_progress:\n",
    "        predicted_reward = model(observation)\n",
    "        action = torch.argmax(predicted_reward, dim=-1).item()\n",
    "        \n",
    "        new_observation, reward, done, truncated, info = env.step(action)\n",
    "        new_observation = torch.from_numpy(new_observation)\n",
    "        \n",
    "        if done == True:\n",
    "            target_reward = torch.tensor(reward)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                predicted_next_reward = model(new_observation)\n",
    "                \n",
    "            max_predicted_next_reward = torch.max(\n",
    "                predicted_next_reward, dim=-1\n",
    "            )\n",
    "            target_reward = reward + GAMMA * max_predicted_next_reward[0]\n",
    "        \n",
    "        loss = loss_func(predicted_reward[action], target_reward)\n",
    "        loss_np = loss.detach().numpy() # can be ignore\n",
    "        losses.append(loss_np)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        if done == True:\n",
    "            in_progress = False\n",
    "            observation, _ = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "18525b33-2f59-4c20-8725-f11159a40054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(8.719359, dtype=float32),\n",
       " array(15.052817, dtype=float32),\n",
       " array(109.01839, dtype=float32)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78e6f22-9332-4dd0-aa89-477e00d29a69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82da08f5-a53a-436f-a9f6-58b6e93759e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
